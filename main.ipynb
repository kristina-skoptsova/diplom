{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5AGu1C+C4Zia4ZMTbkeOW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Автор: Скопцова Кристина Антоновна\n",
        "\n",
        "Тема ВКР: Разработка системы прогнозирования набора абитуриентов на направления подготовки высшего образования"
      ],
      "metadata": {
        "id": "XZ6jBfeNywVM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64HQrbHuFP4b",
        "outputId": "5834d899-0929-455e-9766-45195e831816",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-01 09:10:08--  https://raw.githubusercontent.com/kristina-skoptsova/diplom/refs/heads/main/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 178 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "requirements.txt    100%[===================>]     178  --.-KB/s    in 0s      \n",
            "\n",
            "2025-06-01 09:10:09 (4.27 MB/s) - ‘requirements.txt’ saved [178/178]\n",
            "\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "added 22 packages in 5s\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/kristina-skoptsova/diplom/refs/heads/main/requirements.txt\n",
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка обработанного датасета для  тестирования системы\n",
        "!wget https://raw.githubusercontent.com/kristina-skoptsova/diplom/refs/heads/main/datasets/dataset_muiv.csv"
      ],
      "metadata": {
        "id": "mqbTgDoHuPEQ",
        "outputId": "55a846f1-cb7e-46e3-eeac-b943c1c97624",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-01 09:10:18--  https://raw.githubusercontent.com/kristina-skoptsova/diplom/refs/heads/main/datasets/dataset_muiv.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 916560 (895K) [text/plain]\n",
            "Saving to: ‘dataset_muiv.csv’\n",
            "\n",
            "dataset_muiv.csv    100%[===================>] 895.08K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-06-01 09:10:19 (77.2 MB/s) - ‘dataset_muiv.csv’ saved [916560/916560]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from keras.models import load_model\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import os\n",
        "import tempfile\n",
        "from streamlit_authenticator import Authenticate\n",
        "import requests\n",
        "\n",
        "# Загрузка секретов из GitHub\n",
        "def load_secrets():\n",
        "    secrets_url = 'https://raw.githubusercontent.com/kristina-skoptsova/diplom/refs/heads/main/secrets.toml'\n",
        "    try:\n",
        "        response = requests.get(secrets_url)\n",
        "        if response.status_code == 200:\n",
        "            # Проверка содержимого файла\n",
        "            content = response.text\n",
        "            if '[credentials]' not in content:\n",
        "                st.error('Ошибка: Файл secrets.toml не содержит раздел [credentials]')\n",
        "                return\n",
        "\n",
        "            # Создание папки .streamlit и сохранение\n",
        "            streamlit_dir = os.path.expanduser('~/.streamlit')\n",
        "            os.makedirs(streamlit_dir, exist_ok=True)\n",
        "            secrets_path = os.path.join(streamlit_dir, 'secrets.toml')\n",
        "\n",
        "            with open(secrets_path, 'w') as f:\n",
        "                f.write(content)\n",
        "            st.success('Файл secrets.toml успешно загружен')\n",
        "        else:\n",
        "            st.error(f'Ошибка загрузки: {response.status_code}')\n",
        "    except Exception as e:\n",
        "        st.error(f'Ошибка при загрузке файла: {e}')\n",
        "\n",
        "# Проверка secrets.toml\n",
        "secrets_path = os.path.expanduser('~/.streamlit/secrets.toml')\n",
        "\n",
        "if not os.path.exists(secrets_path):\n",
        "    load_secrets()\n",
        "\n",
        "# Функция аутентификации\n",
        "def authenticate():\n",
        "    if 'authenticated' not in st.session_state:\n",
        "        st.session_state.authenticated = False\n",
        "\n",
        "    if not st.session_state.authenticated:\n",
        "        with st.form('auth_form'):\n",
        "            st.subheader('Авторизация')\n",
        "            username = st.text_input('Логин')\n",
        "            password = st.text_input('Пароль', type='password')\n",
        "            submit_button = st.form_submit_button('Войти')\n",
        "\n",
        "            if submit_button:\n",
        "                if 'credentials' in st.secrets:\n",
        "                    valid_users = st.secrets['credentials']\n",
        "                    if username in valid_users and valid_users[username] == password:\n",
        "                        st.session_state.authenticated = True\n",
        "                        st.rerun()\n",
        "                    else:\n",
        "                        st.error('Неверные учетные данные')\n",
        "                else:\n",
        "                    st.error('Ошибка конфигурации системы')\n",
        "        st.stop()\n",
        "    return True\n",
        "\n",
        "if authenticate():\n",
        "  # Инициализация сессии для хранения состояния\n",
        "  if 'model' not in st.session_state:\n",
        "      st.session_state.model = None\n",
        "  if 'data' not in st.session_state:\n",
        "      st.session_state.data = None\n",
        "  if 'scaler' not in st.session_state:\n",
        "      st.session_state.scaler = RobustScaler()\n",
        "  # Кнопка выхода\n",
        "      if st.sidebar.button('Выйти'):\n",
        "          st.session_state.clear()\n",
        "          st.experimental_rerun()\n",
        "\n",
        "  # Основной интерфейс\n",
        "  st.title('Система прогнозирования набора абитуриентов на направления подготовки высшего образования')\n",
        "  # Создание вкладок\n",
        "  tab1, tab2, tab3 = st.tabs(['Загрузка данных', 'Обучение модели', 'Тестирование модели'])\n",
        "\n",
        "  # Вкладка 1: Загрузка данных\n",
        "  with tab1:\n",
        "      st.header('Загрузка данных')\n",
        "      st.write('Загрузите файл CSV с данными для анализа.')\n",
        "      uploaded_file = st.file_uploader('Выберите файл CSV', type=['csv'])\n",
        "      if uploaded_file is not None:\n",
        "          data = pd.read_csv(uploaded_file)\n",
        "          st.write('Первые 5 строк загруженного файла:')\n",
        "          st.dataframe(data.head())\n",
        "\n",
        "          # Проверка наличия необходимых столбцов\n",
        "          required_columns = {'Направление', 'Год поступления', 'Количество поступивших'}\n",
        "          if not required_columns.issubset(data.columns):\n",
        "              st.error(f'Ошибка: В данных отсутствуют необходимые столбцы: {required_columns}')\n",
        "          else:\n",
        "            # Проверка на пропущенные значения\n",
        "            if data[list(required_columns)].isnull().any().any():\n",
        "                missing_values = data[list(required_columns)].isnull().sum()\n",
        "                st.error(f'Ошибка: Данные содержат пропуски в следующих столбцах:\\n{missing_values[missing_values > 0]}')\n",
        "            # Проверка на дубликаты\n",
        "            elif data.duplicated().any():\n",
        "                duplicates = data.duplicated().sum()\n",
        "                duplicate_rows = data[data.duplicated(keep=False)].sort_values(by=list(data.columns))\n",
        "                st.error(f'Ошибка: Найдено {duplicates} полных дубликатов строк')\n",
        "            else:\n",
        "                # Удаление колонок\n",
        "                columns_to_drop = ['Уровень безработицы', 'Регион рождения', 'Доля наличия договора']\n",
        "                data = data.drop(columns=columns_to_drop)\n",
        "                # Колонки, которые не нужно масштабировать\n",
        "                exclude_columns = ['Направление', 'Год поступления', 'Количество поступивших']\n",
        "                # Колонки для масштабирования\n",
        "                columns_to_scale = [col for col in data.columns if col not in exclude_columns]\n",
        "                # Применение RobustScaler\n",
        "                scaler = RobustScaler()\n",
        "                data[columns_to_scale] = scaler.fit_transform(data[columns_to_scale])\n",
        "                # Сохранение данных\n",
        "                st.session_state.data = data\n",
        "\n",
        "  # Вкладка 2: Обучение модели\n",
        "  with tab2:\n",
        "      st.header('Обучение модели')\n",
        "      if st.session_state.data is None:\n",
        "          st.warning(\"Сначала загрузите данные на вкладке 'Загрузка данных'\")\n",
        "      else:\n",
        "          if st.button('Начать обучение'):\n",
        "              with st.spinner('Обучение модели...'):\n",
        "                  try:\n",
        "                      import tensorflow as tf\n",
        "                      from keras.models import Sequential\n",
        "                      from keras.layers import Dense, Input, LSTM, Dropout\n",
        "                      from sklearn.model_selection import train_test_split\n",
        "                      from sklearn.preprocessing import RobustScaler\n",
        "                      from keras.callbacks import EarlyStopping\n",
        "\n",
        "                      X = st.session_state.data.drop(columns=['Количество поступивших'])\n",
        "                      y = st.session_state.data['Количество поступивших']\n",
        "                      # Функция для создания последовательностей данных\n",
        "                      def create_sequences(data, window_size):\n",
        "                          inputs, outputs, groups = [], [], []\n",
        "                          for direction in data['Направление'].unique():\n",
        "                              dir_data = data[data['Направление'] == direction].sort_values('Год поступления')\n",
        "                              for i in range(len(dir_data) - window_size):\n",
        "                                  seq = dir_data.iloc[i:i+window_size].drop(['Направление', 'Год поступления', 'Количество поступивших'], axis=1).values\n",
        "                                  target = dir_data.iloc[i+window_size]['Количество поступивших']\n",
        "                                  direction_label = dir_data.iloc[i+window_size]['Направление']  # Направление для следующего шага\n",
        "                                  inputs.append(seq)\n",
        "                                  outputs.append(target)\n",
        "                                  groups.append(direction_label)\n",
        "                          return np.array(inputs), np.array(outputs), np.array(groups)\n",
        "\n",
        "                      # Создание последовательностей\n",
        "                      YEARS_SIZE = 5\n",
        "                      X, y, direction_labels = create_sequences(st.session_state.data, YEARS_SIZE)\n",
        "\n",
        "                      # Нормализация целевой переменной\n",
        "                      y_scaler = RobustScaler()\n",
        "                      y = y_scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "                      # Разделение данных на тренировочную и тестовую выборки\n",
        "                      X_train, X_test, y_train, y_test, direction_train, direction_test = train_test_split(\n",
        "                          X, y, direction_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "                      # Сохрание x_test и y_test\n",
        "                      st.session_state.X_test = X_test\n",
        "                      st.session_state.y_test = y_test\n",
        "\n",
        "                      # Рассчитываются веса только для тренировочной выборки\n",
        "                      unique_directions, direction_counts_train = np.unique(direction_train, return_counts=True)\n",
        "                      direction_weights_train = {direction: 1.0 / count for direction, count in zip(unique_directions, direction_counts_train)}\n",
        "\n",
        "                      # Применение весов к данным\n",
        "                      sample_weights = st.session_state.data['Направление'].map(direction_weights_train).values\n",
        "\n",
        "                      # Ограничение веса для тренировочной выборки\n",
        "                      train_sample_weights = sample_weights[:len(y_train)]\n",
        "\n",
        "                      # Архитектура модели\n",
        "                      model_lstm = Sequential([\n",
        "                          Input(shape=(YEARS_SIZE, X.shape[2])),\n",
        "                          LSTM(128, return_sequences=True),\n",
        "                          Dropout(0.1),\n",
        "                          LSTM(64),\n",
        "                          Dense(32, activation='relu'),\n",
        "                          Dense(1)\n",
        "                      ])\n",
        "\n",
        "                      # Компиляция модели\n",
        "                      model_lstm.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
        "\n",
        "                      # Ранняя остановка при переобучении\n",
        "                      early_stopping = EarlyStopping(\n",
        "                          monitor='val_loss',\n",
        "                          patience=10,\n",
        "                          restore_best_weights=True  # Восстановление весов модели с лучшим результатом\n",
        "                      )\n",
        "\n",
        "                      # Обучение модели\n",
        "                      history_lstm = model_lstm.fit(\n",
        "                          X_train,\n",
        "                          y_train,\n",
        "                          sample_weight=train_sample_weights,  # Использование веса\n",
        "                          epochs=100,\n",
        "                          batch_size=64,\n",
        "                          validation_split=0.2,\n",
        "                          callbacks=[early_stopping],\n",
        "                          verbose=1\n",
        "                      )\n",
        "\n",
        "                      # Сохранение модели\n",
        "                      model_lstm.save('lstm_model.keras')\n",
        "                      st.success('Модель успешно обучена и сохранена!')\n",
        "                      st.session_state.model = model_lstm\n",
        "\n",
        "                      # Сохранение scaler для предсказаний\n",
        "                      st.session_state.scaler = y_scaler\n",
        "\n",
        "                      # Визуализация обучения\n",
        "                      st.line_chart(pd.DataFrame(history_lstm.history))\n",
        "\n",
        "                      # Возможность скачивания файла\n",
        "                      with open('lstm_model.keras', 'rb') as file:\n",
        "                        st.download_button(\n",
        "                            label='Скачать модель',\n",
        "                            data=file,\n",
        "                            file_name='lstm_model.keras',\n",
        "                            mime='application/octet-stream'\n",
        "                            )\n",
        "                  except Exception as e:\n",
        "                    st.error(f'Ошибка при обучении модели: {e}')\n",
        "\n",
        "  # Вкладка 3: Тестирование модели\n",
        "  with tab3:\n",
        "      st.header('Тестирование модели')\n",
        "      # Загрузка модели\n",
        "      st.subheader('Загрузка модели')\n",
        "      uploaded_model = st.file_uploader('Выберите файл модели (.keras)', type=['keras'])\n",
        "      if uploaded_model:\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.keras') as tmp_file:\n",
        "          tmp_file.write(uploaded_model.getvalue())\n",
        "          st.session_state.model = load_model(tmp_file.name)\n",
        "        st.success('Модель успешно загружена!')\n",
        "\n",
        "      if st.session_state.model is None:\n",
        "          st.warning('Сначала загрузите или обучите модель')\n",
        "      else:\n",
        "          # Подраздел: Оценка модели\n",
        "          st.subheader('Оценка модели')\n",
        "          if st.button('Оценить модель'):\n",
        "              try:\n",
        "                  # Извлечение тестовых данных\n",
        "                  X_test = st.session_state.X_test\n",
        "                  y_test = st.session_state.y_test\n",
        "\n",
        "                  # Предсказания на тестовых данных\n",
        "                  predictions = st.session_state.model.predict(X_test)\n",
        "                  predictions = st.session_state.scaler.inverse_transform(predictions)\n",
        "                  y_test_original = st.session_state.scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "                  # Оценка качества модели\n",
        "                  from sklearn.metrics import mean_absolute_error, r2_score\n",
        "                  mae = mean_absolute_error(y_test_original, predictions)\n",
        "                  r2 = r2_score(y_test_original, predictions)\n",
        "                  st.write(f'Средняя абсолютная ошибка (MAE): {mae:.2f}')\n",
        "                  st.write(f'Коэффициент детерминации (R²): {r2:.2f}')\n",
        "\n",
        "                  # Отображение результатов\n",
        "                  results = pd.DataFrame({\n",
        "                      'Реальные значения': y_test_original.flatten(),\n",
        "                      'Предсказанные значения': predictions.flatten()\n",
        "                  })\n",
        "                  st.write('Результаты предсказания на тестовых данных:')\n",
        "                  st.dataframe(results)\n",
        "\n",
        "              except Exception as e:\n",
        "                  st.error(f'Ошибка при оценке модели: {e}')\n",
        "          # Подраздел: Прогнозирование\n",
        "          st.subheader('Прогнозирование')\n",
        "          all_directions = st.session_state.data['Направление'].unique().tolist()\n",
        "          forecast_option = st.selectbox('Выберите направления для прогнозирования:', ['Все'] + all_directions)\n",
        "          selected_directions = all_directions if forecast_option == \"Все\" else [forecast_option]\n",
        "          if st.button('Запустить прогнозирование'):\n",
        "              try:\n",
        "                  # Функция для предсказания следующего года\n",
        "                  def predict_next_year(model, df, years_size, y_scaler):\n",
        "                      predictions = []\n",
        "\n",
        "                      for direction in df['Направление'].unique():\n",
        "                          if selected_directions != 'Все' and direction not in selected_directions:\n",
        "                              continue\n",
        "\n",
        "                          dir_data = df[df['Направление'] == direction].sort_values('Год поступления')\n",
        "\n",
        "                          # Если данных недостаточно для создания последовательности, пропускаем направление\n",
        "                          if len(dir_data) < years_size:\n",
        "                              st.write(f'Недостаточно данных для направления {direction}. Требуется минимум {years_size} года.')\n",
        "                              continue\n",
        "\n",
        "                          # Создаем последовательность из последних years_size лет\n",
        "                          last_sequence = dir_data.iloc[-years_size:].drop(['Направление', 'Год поступления', 'Количество поступивших'], axis=1).values\n",
        "                          last_sequence = last_sequence.reshape(1, years_size, last_sequence.shape[1])\n",
        "\n",
        "                          # Нормализуем последовательность\n",
        "                          scaler = RobustScaler()\n",
        "                          last_sequence = scaler.fit_transform(last_sequence.reshape(-1, last_sequence.shape[2])).reshape(last_sequence.shape)\n",
        "\n",
        "                          # Предсказываем количество абитуриентов\n",
        "                          predicted_value = model.predict(last_sequence)\n",
        "\n",
        "                          # Преобразуем предсказание обратно в исходный масштаб\n",
        "                          predicted_value = y_scaler.inverse_transform(predicted_value)[0][0]\n",
        "\n",
        "                          # Сохраняем результат\n",
        "                          predictions.append({\n",
        "                              'Направление': direction,\n",
        "                              'Предсказанное количество абитуриентов': int(round(predicted_value))\n",
        "                          })\n",
        "\n",
        "                      # Создаем DataFrame с результатами\n",
        "                      result_df = pd.DataFrame(predictions)\n",
        "                      return result_df\n",
        "\n",
        "                  # Вызываем функцию предсказания\n",
        "                  YEARS_SIZE = 5\n",
        "                  predictions_df = predict_next_year(st.session_state.model, st.session_state.data, YEARS_SIZE, st.session_state.scaler)\n",
        "\n",
        "                  if predictions_df.empty:\n",
        "                      st.error('Нет данных для выбранных направлений или недостаточно записей для прогнозирования.')\n",
        "                  else:\n",
        "                      # Отображение результатов\n",
        "                      st.write('Прогноз количества абитуриентов на следующий год:')\n",
        "                      st.dataframe(predictions_df)\n",
        "\n",
        "                      # Сохранение результатов прогноза\n",
        "                      predictions_df.to_csv('results.csv', index=False)\n",
        "                      st.success('Результаты прогноза успешно сохранены в файл results.csv!')\n",
        "                      # Возможность скачивания файла\n",
        "                      with open('results.csv', 'rb') as file:\n",
        "                        st.download_button(\n",
        "                            label='Скачать результаты прогноза',\n",
        "                            data=file,\n",
        "                            file_name='results.csv',\n",
        "                            mime='text/csv'\n",
        "                            )\n",
        "              except Exception as e:\n",
        "                  st.error(f'Ошибка при прогнозировании: {e}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atykb5eAFU38",
        "outputId": "aa4804aa-b4ba-42cd-d116-79f12fc10ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "print(\"Пароль:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aymPBocoFc_6",
        "outputId": "7b5eca3d-174a-4de9-86ce-8166e34dd3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пароль: 34.16.157.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501 &>/dev/null & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Supdo2gYFdyw",
        "outputId": "577ac613-1c9d-4f8f-84a4-f35cc718b27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://big-hornets-drop.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}